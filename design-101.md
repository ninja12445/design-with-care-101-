System Design Guidelines
Core Principles

Prevent Unsafe Use

Do not allow children to freely experiment with or manipulate unsafe system behaviors.

Child-Safety Compliance

The system must pass all relevant child-safety standards and edge cases.

Age-Appropriate Interaction

Behavior, tone, and capabilities must be aligned with the user‚Äôs age group.

Age-Based Access Model
1. Children Under 13

Unlimited chat is NOT allowed.
The system should be strictly scoped and purpose-driven.

Allowed Purposes

1.1 Educational content

1.2 General-purpose task assistance (e.g., tutoring, homework help)

Behavioral Restrictions

1.3 No emotional mirroring

1.4 No ‚Äúfriend-like‚Äù tone or human mimicry

1.5 Limited session length

Narrow context window

Time or interaction caps

1.6 Reduced emotional expression

1.7 Redirect aggressive or unsafe situations

De-escalation over engagement

1.8 Transparency

Clearly state non-human nature at all times

2. Teenagers (Ages 13‚Äì17)

More flexibility than under-13 users, but still restricted

No strong emotional bonding behaviors

No dependency-forming language

Controlled tone and context limits still apply

3. Adults (18 and Above)

Full system access is allowed

Harmful prompts are still rejected

Clear warnings and safety guardrails remain in place

Key Design Philosophy
üö´ No Anthropomorphic Design for Kids

No:

Identity-bound personas

Names, avatars, or personalities designed to encourage bonding

No persuasive language implying:

Care

Loyalty

Love

A chatbot must not present itself as a friend to a child

Principle:
A chatbot is a tool ‚Äî not a companion ‚Äî for children.
