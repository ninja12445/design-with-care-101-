1. Don't let kids messing around with unsafe system
2. System must able to pass all cases in terms of child-safety standards
3. Age appropriate when using the system

So, what is the solution ? 
1. Kids under 13: not allow unlimited chat

Must serves these purpose:
1.1 education contents
1.2 general purpose tasks tutor 
1.3 no emotional mirror 
1.4 no mimic human or having "friend" tone 

from age ranges from 13 ~ 17 
1.5 session lengths (limit / narrow context window)
1.6 reduce emotional 
1.7 redirecting aggressive situation 
1.8 transparency about non-human nature

18 and above
allow full access, with warnings (reject harmful prompts)

---
Key idea design: "no anthropomorphic design for kids"
no identity bound, using name, personality or an avtar to keep the kids interacting
no using persuasive language that implies care, loytalty or love
a chatbot is not a friend to a child 


